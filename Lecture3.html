<html>
    <head>
        <link href="style.css" rel="stylesheet" type="text/css"/>
        <title>
            Introduction to Algorithms, Lecture 3
        </title>
    </head>

    <body>
        <h1>
            Introduction to Algorithms, Lecture 3
        </h1>
        <h2>Looking at Memo-ization</h2>
        <p>
            Last class, I asked you to memo-ize the naive, recursive
            Fibonacci algorithm. Let's take a look at how to do that.
            <br>
            <a href="https://github.com/gcallah/algorithms/blob/master/fibonacci.py">Here</a>
            is the Fibonacci code, now including memo-ization.
        </p>
        <h2>Dictionaries</h2>
        <h3>
        Dictionary ADT.
        </h3>
        <p>
        Operations associated with this data type allow:
        <ul>
            <li>the addition of a pair to the collection
            <li>the removal of a pair from the collection
            <li>the modification of an existing pair
            <li>the lookup of a value associated with a particular key
        </ul>
            <p>
            (<a href="https://en.wikipedia.org/wiki/Associative_array">Source</a>)
            </p>

        </p>

        <p>
        (Ordered Dictionary ADT next time.) 
        </p>
        <h3>
        Direct addressing. 
        </h3>
        <ul>
            <li> <em>O(1)</em> time for lookup.
            <li> Uses:
            <ul>
                <li> Memo-ization
                <li> Bingo
                <li> Sieve of Eratosthenes
                <li> Mark zipcodes seen
            </ul>
            <li> Downside: wastes space. If you have no idea how many possible
            keys you need, direct addressing is not a good choice.
            <br>For instance, if your key is an arbitrary string!
            <li><a href="https://github.com/gcallah/algorithms/blob/master/hash.py">
                Example code here.
                </a>
        </ul>
        <h3>
        Hashing
        </h3>
        <p>
        <img
        src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Hash_table_4_1_1_0_0_1_0_LL.svg/300px-Hash_table_4_1_1_0_0_1_0_LL.svg.png">
        <br>
        Review of hashing:
        <ul>
            <li> Open addressing.
            <li> Linear probing.
            <li> Quadratic probing.
            <li> Double hashing. 
        </ul>
        </p>
        <h4>
        How to analyze hashing?
        </h4>
        <p>
        Analysis of expected algorithm behavior under
        some assumptions on the input.

        </p>
        <h4>
        Introducing randomization into an algorithm.
        </h4>
        <p>
        What happens to the usual
        assumptions? Correctness: always, most of the time?
        Termination:
        always, or almost always? What does "performance" mean if the running
        time/answer/even termination change from one run to the next. 
        </p>
        <h4>
        Review of basic probability stuff.
        </h4>
        <p>
        We assume that everyone is familiar with the basic concept of
        probability (do not want to be very formal): what an EVENT is and what
        Prob(EVENT) is.  For example: We are using a fair die.  The usual,
        with six sides and numbers 1, 2, 3, 4, 5, 6 on its sides.  We throw it
        once.  Then the probability of the event A:"4 came out" is 1/6.  The
        probability of the event B:"5 came out" is 1/6. The probability of the
        event C:"an even number came out" is 1/2.  Etc.
        <br>
        <br>

        Very basic rules/laws/definitions of probability:
        <br>
        <br>

        For any two events A, B: Prob(A or B) = Prob(A) + Prob(B) - Prob(A and
        B).
        ["inclusion-exclusion"]
        <br>
        <br>

        From this comes a crude way to estimate probabilities:
          Prob(A or B) <= Prob(A) + Prob(B)
          or more generally
          <br>
            Prob(A_1 or A_2 or ... or A_n) <= sum Prob (A<sub>i</sub>)
            <br>
            <br>

            Two events A, B are <em>mutually exclusive</em> if Prob(A and B) = 0.
            <br>
            <br>

            Two events are <em>independent</em> if Prob(A and B) = Prob(A) *
            Prob(B).
            <br>
            <br>

            Expectations ( =expected values ):
            <br>
            <br>

            Expected value of a real variable <em>X</em> is defined as
            <br>
            <em>E[X]=&Sigma;{x} Prob[X=x] * x</em>
             <br>
             where the sum is taken over all values <em>x</em> that <em>X</em> can take.
             <br>
             In words:
             <br>
             the expected value of a variable is the weighted sum of
             all its
             values, weighted according to the probability that they
             happen.
             <br>
             <br>

             Example: You throw a die and get $10 if it comes out 1 and
             $0 if not.
             <br>
             <br>

             The expected value of your reward is $10 * 1/6 + $0
             * 5/6 = $10/6.
             <br>
             <br>

             You play the lottery.  You pay $1 for the ticket and win
             one million
             dollars with probability 1/(1 billion).  How much do you
             expect to
             win?  What's the expected balance?
             <br>
             <br>

             Expected outcome = -$1 + Expected win.
             <br>
             <br>

             Expected win = $1,000,000 * 1/(1 billion) + $0 * (the
             probability I do not win) = $1/1000 = 0.1cent.
             <br>
             <br>

             So expected outcome = you lose 99.9 cents.
             <br>
             <br>

             Useful properties of expectations:
             <br>
             <br>

             Linearity of expectation:
             <br>
             <br>

             <em>E[a X + b Y] = a E[X] + b E[Y]</em>, for any two events X, Y
             [there are
             some mild requirements on X and Y, but INDEPENDENCE IS NOT
             REQIURED!]
             and constants a, b.
             <br>
             <br>

             Indicator variables:
             <br>
             <br>

             X is an <sub>i</sub>ndicator variable_ for an event A if
             <br>
             <br>

             X = 1 if A happens
             X = 0 if A does not happen
             <br>
             <br>

             Useful properties of indicator variables:
             <br>
             <br>

             If X is an indicator variable for A, then
             Exp[X]=Prob[X=1]=Prob[A happens].
             <br>
             This easily follows from the definition:
             <br>
             Exp[X]=1 * Prob[X=1] + 0 *
             Prob[X=0]=Prob[X=1]=Prob[A happens]
             <br>
             <br>

             Example:
             <br>
             <br>

             We throw a fair die 100 times  What is the expect number
             of times we
             get 1 or 6?
             <br>
             <br>

             Let X<sub>i</sub> be the indicator variable of the event "in ith
             throw we got 1 or 6".
             Then notice that the number of times we get 1 or 6 is
             exactly
             <br>
             <br>

             &Sigma;{i=1}^{100} X<sub>i</sub>
             <br>
             <br>

             and we want the expectation of this.  By linearity of
             expectation:
             <br>
             <br>

             E[&Sigma;{i=1}^{100} X<sub>i</sub>] = &Sigma;{i=1}^{100} E[X<sub>i</sub>]
             <br>
             <br>

             and by the indicator variable properties:
             <br>
             <br>

             E[X<sub>i</sub>]=Prob[X<sub>i</sub>=1]=Prob[we got 1 or 6]=2/6=1/3
             <br>
             <br>

             To summarize:
             <br>
             <br>

             E[&Sigma;{i=1}^{100} X<sub>i</sub>] = &Sigma;{i=1}^{100} 1/3 = 100/3 =
             33.3333...
             <br>
             <br>

             So we expect to get 1 or 6 about 33.33 times.
             <br>
             <br>

             Finally, something that comes up very frequently:
             <br>
             <br>

             Suppose you have a sequence of events, each of which
             happens with
             probability p, independent of the previous ones.  What is
             the expected
             number of tries in the sequence you must observe until you
             see an
             event you like.
             <br>
             <br>

             Examples:
             <br>
             <br>

             Flip a coin several times.  How many tries until it comes
             out heads.
             <br>
             <br>

             Throw a pair of die.  How many tries until they give you
             {6,6}?
             <br>
             <br>

             Play the lottery.  How many tries until you win?
             <br>
             <br>

             Probability event i happens is (1-p)^{i-1}p.  In this case
             you need to
             wait i steps.  So the expected number of steps to wait is
             <br>
             <br>

             &Sigma;{i=1}^\infty i(1-p)^{i-1}p
             <br>
             <br>

             It's a standard summation that adds up to 1/p. [A cute or
             painful
             algebra exercise, depending on how you do it, I guess...]
             <br>
             <br>

             so:
             <br>
             <br>

             Fact: If you have a sequence of independent events, each
             succeeding
             with probability p, the expected number of tries until the
             first
             success is 1/p.
             <br>
             <br>

             Or slightly more generally:
             <br>
             <br>

             Fact: If you have a sequence of independent events, each
             succeeding
             with probability at least p, the expected number of tries
             until the
             first success is at most 1/p.
             <br>
             <br>

             [The last one is useful if you are doing sampling without
             replacement, so the probabilities changes as you go along.]
             <br>
             <br>
        </p>

        <h4>
        Simple uniform hashing assumption.
        </h4>
        <p>
        Analysis of chaining under this
        assumption. Cost of a successful and unsuccessful search as a function
        of the table's load factor. 
        </p>
        <h4>
        Universal sets of hash functions
        </h4>
        <p>
        Miraculously much of the analysis
        works here too, even though model is completely different. 
        <br>
        Static perfect hashing. 
        <br>
        <img
        src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/Hash_table_4_1_0_0_0_0_0_LL.svg/300px-Hash_table_4_1_0_0_0_0_0_LL.svg.png">

        </p>


    </body>
</html>
